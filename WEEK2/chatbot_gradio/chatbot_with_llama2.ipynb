{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c006d3f5-a3c2-4f2f-a690-75c756d33d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ff9433-9af9-4299-8c8e-53b722f41a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.21.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradio.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c173f77e-7afc-4722-8194-b6b859024571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for asking! Both red and blue tomatoes are great options for harvesting, depending on your specific needs and preferences. Here are some factors to consider:\n",
      "\n",
      "1. Taste: Red tomatoes are generally considered to have a more intense flavor than blue tomatoes. If you want a tomato with a bold, tangy taste, red might be the better choice. On the other hand, if you prefer a milder flavor, blue tomatoes could be a good option.\n",
      "2. Nutrition: Blue tomatoes are often higher in antioxidants and have a lower acidity than red tomatoes. This means they may be more nutritious overall, but this can also depend on the specific variety of each color.\n",
      "3. Yield: Red tomatoes tend to produce more fruit per plant than blue tomatoes, so if you want to harvest a lot of tomatoes, red might be the better choice. However, blue tomatoes are often smaller and more compact, which can make them easier to grow in smaller spaces or for those with limited space.\n",
      "4. Disease resistance: Some varieties of blue tomatoes are naturally more resistant to certain diseases, such as fungal infections, than red tomatoes. This can be an important consideration if you live in a humid climate or have experienced issues with disease in the past.\n",
      "5. Color: Of course, one of the most obvious differences between red and blue tomatoes is their color! While both colors are beautiful and delicious, some people may prefer the deep red hue of traditional tomatoes, while others might enjoy the unique blue-gray tint of blue tomatoes.\n",
      "\n",
      "Ultimately, the choice between red and blue tomatoes will depend on your personal preferences and growing conditions. Consider the factors mentioned above and decide which option is best for you!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.api_base = \"http://127.0.0.1:11434\"  # Ensure correct API connection\n",
    "\n",
    "response = ollama.chat(model='llama2', messages=[\n",
    "    {'role': 'user', \n",
    "     'content': 'to harvest, is red tomato or blue tomato better?'}\n",
    "],options={\"num_ctx\": 1024})\n",
    "\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16bd29fa-38f3-4bdf-a614-308f13a4698c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Mirroring\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def respond_message(message,chat_history):\n",
    "    mirroring = message+' '+message \n",
    "    chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": mirroring})\n",
    "\n",
    "    print('my message', message)\n",
    "    print('history',chat_history)\n",
    "\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(type=\"messages\")   \n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "    msg.submit(respond_message, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66770b1e-30cb-4b29-b48d-1ac53ac27edc",
   "metadata": {},
   "source": [
    " *Chatbox works -----> (message,chat_history)*\n",
    "-------------------------------------------------------\n",
    "[\r",
    "-  {\"role\": \"system\", \"content\": \"system message here\"\n",
    "-   {\"role\": \"user\", \"content\": \"first user prompt here\n",
    "-    {\"role\": \"assistant\", \"content\": \"the assistant's respons\n",
    "-     {\"role\": \"user\", \"content\": \"the new user promt]},\r\n",
    "]\n",
    "\n",
    "*Message Sequence*\n",
    "-----------------\n",
    "- The system message comes first.\n",
    "- Then, the history (past messages).\n",
    "- Finally, the new user message.\n",
    "\n",
    "*This is the recommended order because:*\n",
    "-------------------------\n",
    "- The system message sets the context for the conversation.\n",
    "- The history provides prior interactions.\n",
    "- The new user message continues the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017addff-6001-46f8-9f94-1fce784721b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f321941-fd93-472b-b88a-dfec3842886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7891\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7891/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integrate WITH LLM:\n",
    "import gradio as gr\n",
    "\n",
    "def greeting_message():\n",
    "    return {\"role\": \"assistant\", \"content\": 'Hello, how can i help you?'}\n",
    "\n",
    "def system_prompt_msg(question):\n",
    "    system_prompt = \"Please be kind and be straightforward in your answers. Dont eloborate the answers. \"\n",
    "    system_prompt += \"If it is needed to give the examples especially for objective questions, add them in your comments. \"\n",
    "    system_prompt += \"If the questions is very subjective, answer in subjective way\"\n",
    "    system_prompt += f\"here is the question: {question}\"\n",
    "    return {\"role\": \"system\", \"content\": system_prompt}\n",
    "    \n",
    "\n",
    "def user_prompt_msg(question):\n",
    "    return {\"role\": \"user\", \"content\": question}\n",
    "\n",
    "def chatbot(question,msg_history):\n",
    "\n",
    "    if not isinstance(msg_history,list): #initialize msg_history\n",
    "        msg_history = []\n",
    "\n",
    "    if not msg_history: #If it is empty by first call or clear history\n",
    "        msg_history =  [greeting_message(),system_prompt_msg(question)]  \n",
    "        return \"\",msg_history\n",
    "    \n",
    "    #new question comes! then save the new message coming\n",
    "    msg_history.append(user_prompt_msg(question))\n",
    "    \n",
    "    response = ollama.chat(model='llama2', \n",
    "                       messages=msg_history,options={\"num_ctx\": 1024})\n",
    "    \n",
    "    #then save the answer\n",
    "    msg_history.append({\"role\": \"assistant\", \"content\": response['message']['content']})\n",
    "    \n",
    "    #msg_history -> system_message->system_prompt->user_prompt->assistance_prompt\n",
    "    #next messages in the future:\n",
    "    #msg_history -> system_message->system_prompt->user_prompt->assistance_prompt->user_prompt->assistance_prompt\n",
    "    print(msg_history) #for logging\n",
    "  \n",
    "    return '' ,msg_history\n",
    "    \n",
    "\n",
    "# Integrate the Gradio\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gradio_chat = gr.Chatbot(type=\"messages\")   \n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.ClearButton([msg, gradio_chat])\n",
    "    msg.submit(chatbot, [msg, gradio_chat], [msg, gradio_chat])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c143d3d-15f8-4c15-861f-7179b6b1b1db",
   "metadata": {},
   "source": [
    "**It is what exactly i want to see. The history is inside list then each message is in dict.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837b6d79-bff9-47a9-8a75-1e4b7b02aab3",
   "metadata": {},
   "source": [
    "But there is an observation that system message waits for user message typing. This is not my intention. Greeting message needs to be shown before user intereaction:\n",
    "\n",
    "- The key reason is that chatbox needs to be completed the cycle includes user message and assistant message. If i do design it with streaming, it would be solved.\n",
    "\n",
    "- It could be solved by adding value in gr.ChatBox(value ='message printing', type = 'message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ae62b79-1ed5-49c7-93fe-1547da149308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7902\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7902/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'assistant', 'metadata': None, 'content': 'Hello, how can I help you today?', 'options': None}, {'role': 'user', 'content': 'how does the weather look like'}, {'role': 'assistant', 'content': \"I'm just an AI and do not have real-time access to current weather conditions or forecasts. However, I can suggest some ways for you to find out the current weather conditions in your area or any other location:\\n\\n1. Check online weather websites: There are many websites that provide up-to-date weather forecasts and conditions, such as AccuWeather, Weather.com, or the National Weather Service (NWS).\\n2. Use a mobile app: There are many mobile apps available that provide real-time weather information, such as Dark Sky (iOS, Android), Weather Underground (iOS, Android), or The Weather Channel (iOS, Android).\\n3. Tune into local news: You can watch local news broadcasts or check their website for weather updates and forecasts.\\n4. Check social media: Many meteorologists and weather organizations share weather updates and forecasts on social media platforms like Twitter or Facebook.\\n5. Look outside: If you are outside, you can observe the current weather conditions by looking at the sky, wind direction, temperature, and other factors.\"}]\n",
      "[{'role': 'assistant', 'metadata': None, 'content': 'Hello, how can I help you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'how does the weather look like', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': \"I'm just an AI and do not have real-time access to current weather conditions or forecasts. However, I can suggest some ways for you to find out the current weather conditions in your area or any other location:\\n\\n1. Check online weather websites: There are many websites that provide up-to-date weather forecasts and conditions, such as AccuWeather, Weather.com, or the National Weather Service (NWS).\\n2. Use a mobile app: There are many mobile apps available that provide real-time weather information, such as Dark Sky (iOS, Android), Weather Underground (iOS, Android), or The Weather Channel (iOS, Android).\\n3. Tune into local news: You can watch local news broadcasts or check their website for weather updates and forecasts.\\n4. Check social media: Many meteorologists and weather organizations share weather updates and forecasts on social media platforms like Twitter or Facebook.\\n5. Look outside: If you are outside, you can observe the current weather conditions by looking at the sky, wind direction, temperature, and other factors.\", 'options': None}, {'role': 'user', 'content': 'thanks a lot'}, {'role': 'assistant', 'content': \"You're welcome! I hope this helps you find out the current weather conditions. Let me know if you have any other questions.\"}]\n"
     ]
    }
   ],
   "source": [
    "# how to add stream = True:\n",
    "\n",
    "def chatbot(question,msg_history):\n",
    "\n",
    "    if not isinstance(msg_history,list): #initialize msg_history\n",
    "        msg_history = []\n",
    "\n",
    "    if not msg_history: #If it is empty by first call or clear history\n",
    "        msg_history =  [system_prompt_msg(question)]  \n",
    "    \n",
    "    #new question comes! then save the new message coming\n",
    "    msg_history.append(user_prompt_msg(question))\n",
    "    \n",
    "    response = ollama.chat(model='llama2', \n",
    "                       messages=msg_history,options={\"num_ctx\": 1024},stream=True)\n",
    "    \n",
    "\n",
    "    cluster_of_chunk = {\"role\": \"assistant\", \"content\": ''}\n",
    "    msg_history.append(cluster_of_chunk)\n",
    "    \n",
    "    for chunk in response:   # that gives the response chunk by chunk\n",
    "        word = chunk.get(\"message\",{}).get(\"content\",\"\")\n",
    "        cluster_of_chunk['content'] += word\n",
    "        yield \"\",msg_history\n",
    "    \n",
    "    print(msg_history)\n",
    "    \n",
    "    return '' ,msg_history\n",
    "    \n",
    "# Integrate the Gradio\n",
    "initial_value = [{\"role\": \"assistant\", \"content\": \"Hello, how can I help you today?\"}]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gradio_chat = gr.Chatbot(value=initial_value,type = \"messages\")   \n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.ClearButton([msg, gradio_chat])\n",
    "    msg.submit(chatbot, [msg, gradio_chat], [msg, gradio_chat])\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
