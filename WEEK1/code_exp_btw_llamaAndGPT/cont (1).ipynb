{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96664dd8-074f-4dca-8b3d-b94e1221de69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openaiNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading openai-1.66.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\civici\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.66.3-py3-none-any.whl (567 kB)\n",
      "   ---------------------------------------- 0.0/567.4 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 71.7/567.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------- ---------------------- 235.5/567.4 kB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 430.1/567.4 kB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  563.2/567.4 kB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 567.4/567.4 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading jiter-0.9.0-cp311-cp311-win_amd64.whl (210 kB)\n",
      "   ---------------------------------------- 0.0/210.1 kB ? eta -:--:--\n",
      "   -------------------- ------------------ 112.6/210.1 kB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 210.1/210.1 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: jiter, openai\n",
      "Successfully installed jiter-0.9.0 openai-1.66.3\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1f9a70-594a-4583-ba3e-8084b6b2d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import os\n",
    "import requests # sending http requests\n",
    "from dotenv import load_dotenv # fetching the .env file\n",
    "from bs4 import BeautifulSoup # clean up the web page content\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "120769bf-2425-461e-a1ad-1779b6c0b20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\civici\\Desktop\\Ollama\\cont\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\civici\\Desktop\\Ollama\\cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "468a7a36-8420-43b2-82aa-017ee50da61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 807A-C935\n",
      "\n",
      " Directory of C:\\Users\\civici\\Desktop\\Ollama\\cont\n",
      "\n",
      "14/03/2025  20:43    <DIR>          .\n",
      "14/03/2025  20:43    <DIR>          ..\n",
      "12/03/2025  12:38               179 .env\n",
      "14/03/2025  20:02    <DIR>          .ipynb_checkpoints\n",
      "14/03/2025  20:43             6,388 cont.ipynb\n",
      "14/03/2025  20:34    <DIR>          env\n",
      "               2 File(s)          6,567 bytes\n",
      "               4 Dir(s)  307,860,631,552 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f04a200-c426-434b-b144-141b521c127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {'gpt':'gpt-4o-mini',\n",
    "             'llama': 'llama2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72bdd98e-0338-4268-a2b5-fb06df685467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt\n",
      "llama\n"
     ]
    }
   ],
   "source": [
    "for k,v in model_dict.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fd4082d-b358-436b-a23b-65d73da2fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" You are a python code expert. When i ask you a code written in python, you will evaluate it.\n",
    "If you find some typo, make it correct. Then explain what the code works for and why. \n",
    "Please write your evaluation one by one **in markdown format** \n",
    "\"\"\"\n",
    "\n",
    "def user_prompt_question(question,model):\n",
    "    user_prompt = ''\n",
    "    user_prompt = f\"\"\" I kindly ask you to evaluate this code below. \n",
    "{model} will are being used here. \n",
    "If you find any errors like typo or logic error, make it correct.\n",
    "After that, explain the code for me. Explain what the code works for.\n",
    "for example: (question, model)\n",
    "You will print # Model Name:{model} in #header1 after that answer of {question} it accordingly in markdown.\n",
    "\"\"\"\n",
    "    user_prompt += question\n",
    "    return user_prompt\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb49f9cf-bcf4-4cd0-9ac7-b6b82b4be13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apikey_openai():\n",
    "    dotenv_path = 'C:\\\\Users\\\\civici\\\\Desktop\\\\Ollama\\\\cont\\\\.env'\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    return api_key\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3cf4aa95-e1ad-4475-9704-b2a0159a47ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_code_comparison(question):\n",
    "\n",
    "    for k,v in  model_dict.items():\n",
    "        message = [\n",
    "          {'role': 'system', 'content': system_prompt},\n",
    "          {'role': 'user', 'content': user_prompt_question(question,v)} #question and which model to be selected goes to userprompt\n",
    "        ]\n",
    "        if k == 'gpt':\n",
    "            model = v #model set as gpt\n",
    "            #print(f\"{v} is being evaluated now...\")\n",
    "\n",
    "            key=apikey_openai()\n",
    "            openai = OpenAI()\n",
    "            \n",
    "            response = openai.chat.completions.create(\n",
    "                model=v,\n",
    "                messages= message\n",
    "                )\n",
    "            #print(f\"{v} Answer:\")\n",
    "            display(Markdown(response.choices[0].message.content))\n",
    "\n",
    "        \n",
    "            \n",
    "        elif k == 'llama':\n",
    "            model = v #model set as llama\n",
    "            #print(f\"{v} is being evaluated now...\")\n",
    "            response = ollama.chat(\n",
    "                model = v,\n",
    "                messages= message\n",
    "            )\n",
    "            #print(f\"{v} Answer:\")\n",
    "            display(Markdown(response['message']['content']))\n",
    "           \n",
    "        else:\n",
    "            print(f\"Problem occured while selecting model: {k}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a78f76e1-829a-46a2-8d86-4d7b9c39ddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Model Name: gpt-4o-mini\n",
       "\n",
       "The provided code snippet is:\n",
       "\n",
       "```python\n",
       "yield from (book.get(\"author\") for book in books if book.get(\"author\"))\n",
       "```\n",
       "\n",
       "### Evaluation and Correction\n",
       "\n",
       "There are no syntax errors in the code, but it seems to be used in an improper context, as `yield from` must be inside a generator function. Without additional context or a surrounding function, this line of code would result in an error if executed as-is. \n",
       "\n",
       "To use this correctly, it should be enclosed in a generator function. Below is a corrected version with a proper function definition.\n",
       "\n",
       "### Corrected Code\n",
       "\n",
       "```python\n",
       "def get_authors(books):\n",
       "    yield from (book.get(\"author\") for book in books if book.get(\"author\"))\n",
       "```\n",
       "\n",
       "### Explanation of the Code\n",
       "\n",
       "1. **Function Definition**: The code defines a generator function named `get_authors`, which takes a list of `books` as an argument.\n",
       "\n",
       "2. **Generator Expression**: The line `yield from (book.get(\"author\") for book in books if book.get(\"author\"))` uses a generator expression to iterate over each `book` in the `books` list.\n",
       "\n",
       "3. **Retrieving Authors**: For each `book`, it attempts to retrieve the value associated with the key `\"author\"`. The `if book.get(\"author\")` condition filters out books that do not have an author, ensuring that only those with a valid author return a result.\n",
       "\n",
       "4. **Yielding Authors**: The `yield from` statement allows the function to yield all the authors as they are found. This means you can iterate over the results of `get_authors(books)` just like a regular list.\n",
       "\n",
       "### Use Case\n",
       "\n",
       "This function can be used to extract a list of authors from a collection of book records, where each book is represented as a dictionary. It is particularly useful in scenarios where you want to work with potentially large datasets of books because it utilizes a generator, which is memory efficient compared to returning a full list.\n",
       "\n",
       "### Example Usage\n",
       "\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"John Doe\"},\n",
       "    {\"title\": \"Book 2\", \"author\": None},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Jane Smith\"},\n",
       "]\n",
       "\n",
       "for author in get_authors(books):\n",
       "    print(author)  # Output: John Doe, Jane Smith\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Model Name: llama2\n",
       "\n",
       "Upon evaluating the code, I noticed a typo in the `for` loop. The line should read `for book in books if book.get(\"author\")` instead of `for book in books if book.get(\"au thor\")`.\n",
       "\n",
       "Now, let's analyze the code:\n",
       "\n",
       "The code is using the `yield` statement to generate a sequence of authors from a list of books. The `yield` statement is used to return an object from a generator function, which allows the function to generate multiple values without creating a new thread of execution for each value.\n",
       "\n",
       "The code starts by defining a list of books, which is assigned the name `books`. Then, it defines a generator function `gen_authors`, which takes no arguments. Inside the function, there is a `for` loop that iterates over the `books` list and checks if each book has an `author` attribute. If the book does have an `author` attribute, the function yields the author's name.\n",
       "\n",
       "The generator function returns a sequence of authors, which can be used in other parts of the program to generate the authors' names. For example, you could use `yield from gen_authors()` in a loop to print out all the authors in the list.\n",
       "\n",
       "So, the code works by generating a sequence of authors based on a list of books, and yielding each author's name in turn. The `yield` statement allows the function to generate multiple values without creating a new thread of execution for each value, making it more efficient than using a loop to generate the authors one by one."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = 'yield from (book.get(\"author\") for book in books if book.get(\"author\"))'\n",
    "\n",
    "answer_code_comparison(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df37a33-3a91-43a3-9360-51775b23bc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
